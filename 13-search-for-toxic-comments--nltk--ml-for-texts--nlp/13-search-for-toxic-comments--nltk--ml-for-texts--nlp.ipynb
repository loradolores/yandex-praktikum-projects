{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поиск токсичных комментариев (с NLTK)\n",
    "\n",
    "<h2> (Тема №13: Машинное обучение для текстов) <a class=\"tocSkip\"> </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1. Содержание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1. Содержание](#1)\n",
    "\n",
    "[2. Описание проекта](#2)\n",
    "\n",
    "*    [2.1. Цель проекта](#21)\n",
    "*    [2.2. Задачи проекта](#22)\n",
    "*    [2.3. Описание данных](#23)\n",
    "*    [2.4. План работы](#24)\n",
    "\n",
    "[3. Подготовка данных](#3)\n",
    "\n",
    "*    [3.1. Изучение данных](#31)\n",
    "*    [3.2. Очистка данных](#32)\n",
    "*    [3.3. Лемматизация `WordNetLemmatizer`](#33)\n",
    "*    [3.4. Лемматизация `WordNetLemmatizer` с *POS*-тегами](#34)\n",
    "*    [3.5. Вывод](#35)\n",
    "\n",
    "[4. Обучение моделей](#4)\n",
    "\n",
    "*    [4.1. Разделение данных на выборки](#41)\n",
    "*    [4.2. `LogisticRegression`](#42)\n",
    "\n",
    "        *    [4.2.1. `model_lr`](#421)\n",
    "        *    [4.2.2. `model_lr_pos`](#422)\n",
    "    \n",
    "    \n",
    "*    [4.3. `DecisionTreeClassifier`](#43)\n",
    "\n",
    "        *    [4.3.1. `model_dt`](#431)\n",
    "        *    [4.3.2. `model_dt_pos`](#432)\n",
    "\n",
    "\n",
    "*    [4.4. `LGBMClassifier`](#44)\n",
    "\n",
    "        *    [4.4.1. `model_lgbm50`](#441)\n",
    "        *    [4.4.2. `model_lgbm50_pos`](#442)\n",
    "        *    [4.4.3. `model_lgbm500`](#443)\n",
    "        *    [4.4.4. `model_lgbm500_pos`](#444)\n",
    "\n",
    "\n",
    "*    [4.5. Сравнение моделей](#45)\n",
    "*    [4.6. Вывод](#46)\n",
    "\n",
    "[5. Тестирование лучшей модели](#5)\n",
    "\n",
    "*    [5.1. Качество модели](#51)\n",
    "*    [5.2. Вывод](#52)\n",
    "\n",
    "[6. Общий вывод](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "## 2. Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Обучим модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Построим модель со значением метрики качества *F1* не меньше 0.75. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"21\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 2.1. Цель проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Провести исследование с целью построения модели машинного обучения, которая поможет классифицировать комментарии на позитивные и негативные.\n",
    "\n",
    "Результаты исследования позволят магазину искать токсичные комментарии и отправлять их на модерацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"22\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 2.2. Задачи проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решим поставленную в проекте задачу **с помощью библиотеки *NLTK***.\n",
    "\n",
    "1. Изучить данные.\n",
    "2. Подготовить данные.\n",
    "3. Лемматизировать данные.\n",
    "4. Построить и обучить модели.\n",
    "5. Протестировать лучшую модель.\n",
    "6. Написать общий вывод.\n",
    "\n",
    "Построим модель со значением метрики качества *F1* не меньше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"23\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 2.3. Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`.\n",
    "\n",
    "Столбец `text` в нём содержит текст комментария, а `toxic` — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"24\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 2.4. План работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Изучим данные.\n",
    "2. Очистим комментарии **с помощью библиотеки *NLTK***: переведём буквы в нижний регистр, оставим только латиницу, удалим стоп-слова. \n",
    "3. Лемматизируем комментарии без учёта части речи (без *POS*-тегов) **с помощью библиотеки *NLTK***.\n",
    "4. Лемматизируем комментарии с учётом части речи (с *POS*-тегами) **с помощью библиотеки *NLTK***.\n",
    "5. Разделим данные на обучающую и тестовую выборки для данных без *POS*-тегов и с *POS*-тегами.\n",
    "6. Рассчитаем величину *TF-IDF* для данных без *POS*-тегов и с *POS*-тегами.\n",
    "7. Обучим восемь моделей (`LogisticRegression`, `DecisionTreeClassifier` и `LGBMClassifier` с количеством деревьев `n_estimators`=50 и `n_estimators`=500) для данных без *POS*-тегов и с *POS*-тегами.\n",
    "8. Сравненим модели.\n",
    "9. Протестируем лучшую модель и напишем вывод."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "## 3. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from IPython.display import display\n",
    "from lightgbm import LGBMClassifier\n",
    "from nltk.corpus import stopwords as nltk_stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "RANDOM_STATE = 12345\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"31\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 3.1. Изучение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    try:\n",
    "        data = pd.read_csv(r'C:/Users/lorad/OneDrive/Documents/Моя папка/Data Science/Курсы/'\n",
    "                            'Яндекс.Практикум. Специалист по Data Science/Проектная работа/'\n",
    "                            '13. Машинное обучение для текстов/toxic_comments.csv')\n",
    "    except:\n",
    "        try:\n",
    "            data = pd.read_csv(r'D:/Юлия/Data Science/Курсы/'\n",
    "                                'Яндекс.Практикум. Специалист по Data Science/Проектная работа/'\n",
    "                                '13. Машинное обучение для текстов/toxic_comments.csv')\n",
    "        except:\n",
    "            data = pd.read_csv('https://docs.google.com/spreadsheets/d/e/'\n",
    "            '2PACX-1vQ59JmNL2DruMdFkZoOga-GFUBVFTSgDnVt4Pt7SErYdQQ7hHrTSzRaBHYMhpwa_K4xlnKs_8zrW6di/'\n",
    "                               'pub?gid=1802044232&single=true&output=csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60808</th>\n",
       "      <td>60875</td>\n",
       "      <td>\"\\n\\n Metasemiotics \\n\\nAs a journal editor my...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46287</th>\n",
       "      <td>46342</td>\n",
       "      <td>\"\\n\\n Article Licensing \\n\\nWhenever I need a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2525</th>\n",
       "      <td>2525</td>\n",
       "      <td>2 Operational Conversion Unit RAAF</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151500</th>\n",
       "      <td>151656</td>\n",
       "      <td>\"\\n Read your \"\"sources\"\". Their tone, content...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107284</th>\n",
       "      <td>107381</td>\n",
       "      <td>I ant all the bithces</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "60808        60875  \"\\n\\n Metasemiotics \\n\\nAs a journal editor my...      0\n",
       "46287        46342  \"\\n\\n Article Licensing \\n\\nWhenever I need a ...      0\n",
       "2525          2525                 2 Operational Conversion Unit RAAF      0\n",
       "151500      151656  \"\\n Read your \"\"sources\"\". Their tone, content...      0\n",
       "107284      107381                              I ant all the bithces      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет имеет большой размер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159292, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159292.000000</td>\n",
       "      <td>159292.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>79725.697242</td>\n",
       "      <td>0.101612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>46028.837471</td>\n",
       "      <td>0.302139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39872.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79721.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>119573.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>159450.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0          toxic\n",
       "count  159292.000000  159292.000000\n",
       "mean    79725.697242       0.101612\n",
       "std     46028.837471       0.302139\n",
       "min         0.000000       0.000000\n",
       "25%     39872.750000       0.000000\n",
       "50%     79721.500000       0.000000\n",
       "75%    119573.250000       0.000000\n",
       "max    159450.000000       1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим наличие явных дубликатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитаем количество классов в таргете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    143106\n",
       "1     16186\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдается сильный дисбаланс классов в таргете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"32\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 3.2. Очистка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем решать поставленную в проекте задачу **с помощью библиотеки *NLTK*** (англ. *Natural Language Toolkit*, «инструментарий естественного языка») — ведущая платформа для создания NLP-программ на Python.\n",
    "\n",
    "Напишем функцию `clear_text()`, которая очищает комментарии: переводит буквы в нижний регистр, оставляет только латиницу, удаляет стоп-слова (`stop_words`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    stop_words = set(nltk_stopwords.words('english'))\n",
    "    # переведём в нижний регистр\n",
    "    text = text.lower()\n",
    "    # оставим только латиницу\n",
    "    word_list = re.sub(r\"[^a-z ]\", ' ', text).split()\n",
    "    # удалим stop_words\n",
    "    word_notstop_list = [w for w in word_list if not w in stop_words]\n",
    "    \n",
    "    return ' '.join(word_notstop_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в датасет новый признак `clean_text` с очищенными комментариями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 36.4 s\n",
      "Wall time: 36.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data['clean_text'] = data['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем полученный датасет `data` с новым признаком `clean_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29583</th>\n",
       "      <td>29622</td>\n",
       "      <td>\"Welcome\\n\\nHello, and welcome to Wikipedia! T...</td>\n",
       "      <td>0</td>\n",
       "      <td>welcome hello welcome wikipedia thank contribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29688</th>\n",
       "      <td>29727</td>\n",
       "      <td>look better than that.</td>\n",
       "      <td>0</td>\n",
       "      <td>look better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104956</th>\n",
       "      <td>105053</td>\n",
       "      <td>Table \\n\\n split the table into two: x86 and x...</td>\n",
       "      <td>0</td>\n",
       "      <td>table split table two x x instruction set remo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80705</th>\n",
       "      <td>80781</td>\n",
       "      <td>He was a racial Jew, you fool. If you want to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>racial jew fool want argue appropriate discuss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27785</th>\n",
       "      <td>27822</td>\n",
       "      <td>Fine, I've pulled the mechanics textbooks out ...</td>\n",
       "      <td>0</td>\n",
       "      <td>fine pulled mechanics textbooks bookshelf two ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic  \\\n",
       "29583        29622  \"Welcome\\n\\nHello, and welcome to Wikipedia! T...      0   \n",
       "29688        29727                             look better than that.      0   \n",
       "104956      105053  Table \\n\\n split the table into two: x86 and x...      0   \n",
       "80705        80781  He was a racial Jew, you fool. If you want to ...      1   \n",
       "27785        27822  Fine, I've pulled the mechanics textbooks out ...      0   \n",
       "\n",
       "                                               clean_text  \n",
       "29583   welcome hello welcome wikipedia thank contribu...  \n",
       "29688                                         look better  \n",
       "104956  table split table two x x instruction set remo...  \n",
       "80705   racial jew fool want argue appropriate discuss...  \n",
       "27785   fine pulled mechanics textbooks bookshelf two ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"33\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 3.3. Лемматизация `WordNetLemmatizer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Wordnet* – это большая, свободно распространяемая и общедоступная лексическая база данных для английского языка с целью установления структурированных семантических отношений между словами. Для того, чтобы лемматизировать комментарии, нужно создать экземпляр `WordNetLemmatizer` и вызвать функцию `lemmatize()` для одного слова.\n",
    "\n",
    "Лемматизируем комментарии без учёта части речи (без *POS*-тегов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemm_text(text):\n",
    "    # создадим объект класса для лемматизации\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_list = text.split()\n",
    "    lemmatized_text = ' '.join([lemmatizer.lemmatize(w) for w in word_list])\n",
    "    \n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в датасет новый признак `wnl_text` с комментариями, лемматизированными без *POS*-тегов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "время выполнения лемматизации: 29 s\n",
      "CPU times: total: 29.2 s\n",
      "Wall time: 29.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "beg_time = datetime.datetime.now()\n",
    "data['wnl_text'] = data['clean_text'].apply(lemm_text)\n",
    "data_lemm_time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print(f'время выполнения лемматизации: {data_lemm_time} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"34\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 3.4. Лемматизация `WordNetLemmatizer` с *POS*-тегами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизируем комментарии с учётом части речи (с *POS*-тегами) **с помощью библиотеки *NLTK***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "    # сопоставим POS-тег с первым символом, \n",
    "    # который принимает функция lemmatize()\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    \n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postag_lemm_text(text):\n",
    "    # создадим объект класса для лемматизации с учетом POS-тегов\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    word_list = text.split()\n",
    "    lemmatized_text = ' '.join([\n",
    "        lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in word_list\n",
    "    ])\n",
    "    \n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в датасет новый признак `wnlpostag_text` с комментариями, лемматизированными с *POS*-тегами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "время выполнения лемматизации с POS-тегами: 2740 s\n",
      "CPU times: total: 45min 32s\n",
      "Wall time: 45min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "beg_time = datetime.datetime.now()\n",
    "data['wnlpostag_text'] = data['clean_text'].apply(postag_lemm_text)\n",
    "data_lemm_pos_time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print(f'время выполнения лемматизации с POS-тегами: {data_lemm_pos_time} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndata.to_csv('data_lemm2.csv', index=False)\\ndata = pd.read_csv('data_lemm2.csv')\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# промежуточно сохраняем файл с очищенными и лемматизированными комментариями\n",
    "'''\n",
    "data.to_csv('data_lemm2.csv', index=False)\n",
    "data = pd.read_csv('data_lemm2.csv')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем полученный датасет `data` с новыми признаками `wnl_text` и `wnlpostag_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>131354</th>\n",
       "      <th>22924</th>\n",
       "      <th>27938</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>131490</td>\n",
       "      <td>22944</td>\n",
       "      <td>27975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>Pararphrase manifesto \\nI think we are allowed...</td>\n",
       "      <td>Your general not coolitude \\n\\nIs this the bes...</td>\n",
       "      <td>\"\\n\\nE Robinson (1838) calls it \"\"a copious st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clean_text</th>\n",
       "      <td>pararphrase manifesto think allowed paraphrase...</td>\n",
       "      <td>general coolitude best banned kinghy permanent...</td>\n",
       "      <td>e robinson calls copious stream whatever means...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wnl_text</th>\n",
       "      <td>pararphrase manifesto think allowed paraphrase...</td>\n",
       "      <td>general coolitude best banned kinghy permanent...</td>\n",
       "      <td>e robinson call copious stream whatever mean g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wnlpostag_text</th>\n",
       "      <td>pararphrase manifesto think allow paraphrase m...</td>\n",
       "      <td>general coolitude best ban kinghy permanently ...</td>\n",
       "      <td>e robinson call copious stream whatever mean g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           131354  \\\n",
       "Unnamed: 0                                                 131490   \n",
       "text            Pararphrase manifesto \\nI think we are allowed...   \n",
       "toxic                                                           0   \n",
       "clean_text      pararphrase manifesto think allowed paraphrase...   \n",
       "wnl_text        pararphrase manifesto think allowed paraphrase...   \n",
       "wnlpostag_text  pararphrase manifesto think allow paraphrase m...   \n",
       "\n",
       "                                                           22924   \\\n",
       "Unnamed: 0                                                  22944   \n",
       "text            Your general not coolitude \\n\\nIs this the bes...   \n",
       "toxic                                                           1   \n",
       "clean_text      general coolitude best banned kinghy permanent...   \n",
       "wnl_text        general coolitude best banned kinghy permanent...   \n",
       "wnlpostag_text  general coolitude best ban kinghy permanently ...   \n",
       "\n",
       "                                                           27938   \n",
       "Unnamed: 0                                                  27975  \n",
       "text            \"\\n\\nE Robinson (1838) calls it \"\"a copious st...  \n",
       "toxic                                                           0  \n",
       "clean_text      e robinson calls copious stream whatever means...  \n",
       "wnl_text        e robinson call copious stream whatever mean g...  \n",
       "wnlpostag_text  e robinson call copious stream whatever mean g...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.sample(3).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"35\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 3.5. Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В разделе [**Подготовка данных**](#3.-Подготовка-данных) были выполнены следующие задачи:\n",
    "1. данные изучены;\n",
    "2. комментарии очищены: буквы переведены в нижний регистр, оставлена только латиница, стоп-слова удалены; \n",
    "3. комментарии лемматизированы без учёта части речи (без *POS*-тегов);\n",
    "4. комментарии лемматизированы с учётом части речи (с *POS*-тегами).\n",
    "\n",
    "\n",
    "В результате выполнения задач этого раздела было выявлено следующее:\n",
    "1. пропусков в данных нет;\n",
    "2. типы данных соответствуют требованиям для последующей очистки и лемматизации комментариев;\n",
    "3. датасет имеет большой размер: содержит 159 292 текстовых комментария;\n",
    "4. явных дубликатов нет;\n",
    "5. наблюдается сильный дисбаланс классов в таргете.\n",
    "\n",
    "**В проекте решается задача бинарной классификации.**\n",
    "\n",
    "Таким образом, данные подготовлены для обучения моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "## 4. Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"41\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 4.1. Разделение данных на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зададим параметры для кроссвалидации: `n_splits` - количество фолдов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, random_state=RANDOM_STATE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую и тестовую выборки для обоих признаков `wnl_text` и `wnlpostag_text` в соотношении 4:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    data['wnl_text'], data['toxic'].values, test_size=TEST_SIZE, stratify=data['toxic'].values, \n",
    "    shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_pos, features_test_pos, target_train_pos, target_test_pos = train_test_split(\n",
    "    data['wnlpostag_text'], data['toxic'].values, test_size=TEST_SIZE, stratify=data['toxic'].values, \n",
    "    shuffle=True, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка важности слова определяется величиной *TF-IDF* (от англ. *term frequency*, «частота терма, или слова»; *inverse document frequency*, «обратная частота документа, или текста»). То есть *TF* отвечает за количество упоминаний слова в отдельном тексте, а *IDF* отражает частоту его употребления во всём корпусе.\n",
    "\n",
    "Рассчитаем *TF-IDF* для обоих признаков `wnl_text` и `wnlpostag_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf = TfidfVectorizer()\n",
    "tf_idf_train = count_tf_idf.fit_transform(features_train)\n",
    "tf_idf_test = count_tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_tf_idf_pos = TfidfVectorizer()\n",
    "tf_idf_train_pos = count_tf_idf_pos.fit_transform(features_train_pos)\n",
    "tf_idf_test_pos = count_tf_idf_pos.transform(features_test_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обоих признаков `wnl_text` и `wnlpostag_text`обучим восемь моделей (`LogisticRegression`, `DecisionTreeClassifier` и `LGBMClassifier` с количеством деревьев `n_estimators`=50 и `n_estimators`=500). Для обучения моделей используем функцию `cross_val_score()`. Учтём баланс классов в модели с помощью параметра `class_weight`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"42\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 4.2. `LogisticRegression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **логистической регрессии *Logistic Regression*** для обоих признаков `wnl_text` и `wnlpostag_text`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"421\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "#### 4.2.1. `model_lr`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **логистической регрессии *Logistic Regression*** для признака `wnl_text` (без *POS*-тегов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.753\n",
      "модель: LogisticRegression\n",
      "данные: wnl_text\n",
      "время работы модели: 6 s\n",
      "CPU times: total: 54.6 s\n",
      "Wall time: 6.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_lr = LogisticRegression(solver='liblinear', \n",
    "                              class_weight='balanced', \n",
    "                              random_state=RANDOM_STATE)\n",
    "\n",
    "model_lr.mod = 'model_lr'\n",
    "model_lr.name = 'LogisticRegression'\n",
    "model_lr.data = 'wnl_text'\n",
    "model_lr.f1 = cross_val_score(model_lr,\n",
    "                              tf_idf_train, \n",
    "                              target_train, \n",
    "                              cv=kfold, \n",
    "                              scoring='f1')\n",
    "\n",
    "model_lr.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_lr.f1.mean()))\n",
    "print('модель:', model_lr.name)\n",
    "print('данные:', model_lr.data)\n",
    "print(f'время работы модели: {model_lr.time} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- метрика `f1`: 0.753\n",
    "- модель: `LogisticRegression` \n",
    "- данные: `wnl_text`\n",
    "- время работы модели: 5 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"422\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "#### 4.2.2. `model_lr_pos`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **логистической регрессии *Logistic Regression*** для признака `wnlpostag_text` (с *POS*-тегами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.752\n",
      "модель: LogisticRegression\n",
      "данные: wnlpostag_text\n",
      "время работы модели: 7 s\n",
      "CPU times: total: 56.8 s\n",
      "Wall time: 7.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_lr_pos = LogisticRegression(solver='liblinear', \n",
    "                                  class_weight='balanced', \n",
    "                                  random_state=RANDOM_STATE)\n",
    "\n",
    "model_lr_pos.mod = 'model_lr_pos'\n",
    "model_lr_pos.name = 'LogisticRegression'\n",
    "model_lr_pos.data = 'wnlpostag_text'\n",
    "model_lr_pos.f1 = cross_val_score(model_lr_pos, \n",
    "                                  tf_idf_train_pos, \n",
    "                                  target_train_pos, \n",
    "                                  cv=kfold, \n",
    "                                  scoring='f1')\n",
    "\n",
    "model_lr_pos.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_lr_pos.f1.mean()))\n",
    "print('модель:', model_lr_pos.name)\n",
    "print('данные:', model_lr_pos.data)\n",
    "print(f'время работы модели: {model_lr_pos.time} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- метрика `f1`: 0.752\n",
    "- модель: `LogisticRegression` \n",
    "- данные: `wnlpostag_text` \n",
    "- время работы модели: 5 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"43\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 4.3. `DecisionTreeClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **дерева решений *Decision Tree*** для обоих признаков `wnl_text` и `wnlpostag_text`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"431\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "#### 4.3.1. `model_dt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **дерева решений *Decision Tree*** для признака `wnl_text` (без *POS*-тегов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.618\n",
      "модель: DecisionTreeClassifier\n",
      "данные: wnl_text\n",
      "время работы модели: 175 s\n",
      "CPU times: total: 2min 56s\n",
      "Wall time: 2min 55s\n",
      "Parser   : 125 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_dt = DecisionTreeClassifier(max_depth=15, \n",
    "                                  class_weight='balanced', \n",
    "                                  random_state=RANDOM_STATE)\n",
    "\n",
    "model_dt.mod = 'model_dt'\n",
    "model_dt.name = 'DecisionTreeClassifier'\n",
    "model_dt.data = 'wnl_text'\n",
    "model_dt.f1 = cross_val_score(model_dt, \n",
    "                              tf_idf_train, \n",
    "                              target_train, \n",
    "                              cv=kfold, \n",
    "                              scoring='f1')\n",
    "\n",
    "model_dt.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_dt.f1.mean()))\n",
    "print('модель:', model_dt.name)\n",
    "print('данные:', model_dt.data)\n",
    "print(f'время работы модели: {model_dt.time} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- метрика `f1`: 0.618\n",
    "- модель: `DecisionTreeClassifier`\n",
    "- глубина дерева: `max_depth` = 15\n",
    "- данные: `wnl_text`\n",
    "- время работы модели: 85 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"432\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "#### 4.3.2. `model_dt_pos`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **дерева решений *Decision Tree*** для признака `wnlpostag_text` (с *POS*-тегами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.625\n",
      "модель: DecisionTreeClassifier\n",
      "данные: wnlpostag_text\n",
      "время работы модели: 171 s\n",
      "CPU times: total: 2min 51s\n",
      "Wall time: 2min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_dt_pos = DecisionTreeClassifier(max_depth=15,\n",
    "                                      class_weight='balanced', \n",
    "                                      random_state=RANDOM_STATE)\n",
    "\n",
    "model_dt_pos.mod = 'model_dt_pos'\n",
    "model_dt_pos.name = 'DecisionTreeClassifier'\n",
    "model_dt_pos.data = 'wnlpostag_text'\n",
    "model_dt_pos.f1 = cross_val_score(model_dt_pos, \n",
    "                                  tf_idf_train_pos, \n",
    "                                  target_train_pos, \n",
    "                                  cv=kfold, \n",
    "                                  scoring='f1')\n",
    "\n",
    "model_dt_pos.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_dt_pos.f1.mean()))\n",
    "print('модель:', model_dt_pos.name)\n",
    "print('данные:', model_dt_pos.data)\n",
    "print(f'время работы модели: {model_dt_pos.time} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- метрика `f1`: 0.625\n",
    "- модель: `DecisionTreeClassifier`\n",
    "- глубина дерева: `max_depth` = 15\n",
    "- данные: `wnlpostag_text` \n",
    "- время работы модели: 85 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"44\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 4.4. `LGBMClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **градиентного бустинга *LightGBM*** с количеством деревьев `n_estimators`=50 и `n_estimators`=500 для обоих признаков `wnl_text` и `wnlpostag_text`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"441\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "#### 4.4.1. `model_lgbm50`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **градиентного бустинга *LightGBM*** с количеством деревьев `n_estimators`=50 для признака `wnl_text` (без *POS*-тегов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.724\n",
      "модель: LGBMClassifier 50\n",
      "данные: wnl_text\n",
      "время работы модели: 56 s\n",
      "CPU times: total: 6min 45s\n",
      "Wall time: 56.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_lgbm50 = LGBMClassifier(n_estimators=50,\n",
    "                              max_depth=10,\n",
    "                              learning_rate=0.15,\n",
    "                              class_weight='balanced', \n",
    "                              boosting_type='gbdt', \n",
    "                              objective='binary', \n",
    "                              random_state=RANDOM_STATE,\n",
    "                              # отключение прогресса обучения модели\n",
    "                              verbose=-1)\n",
    "\n",
    "model_lgbm50.mod = 'model_lgbm50'\n",
    "model_lgbm50.name = 'LGBMClassifier 50'\n",
    "model_lgbm50.data = 'wnl_text'\n",
    "model_lgbm50.f1 = cross_val_score(model_lgbm50, \n",
    "                                  tf_idf_train, \n",
    "                                  target_train, \n",
    "                                  cv=kfold, \n",
    "                                  scoring='f1')\n",
    "\n",
    "model_lgbm50.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_lgbm50.f1.mean()))\n",
    "print('модель:', model_lgbm50.name)\n",
    "print('данные:', model_lgbm50.data)\n",
    "print(f'время работы модели: {model_lgbm50.time} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- метрика `f1`: 0.724\n",
    "- модель: `LGBMClassifier`\n",
    "- количество деревьев: `n_estimators` = 50\n",
    "- глубина дерева: `max_depth` = 10\n",
    "- коэффициент скорости обучения: `learning_rate` = 0.15\n",
    "- данные: `wnl_text`  \n",
    "- время работы модели: 42 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"442\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "#### 4.4.2. `model_lgbm50_pos`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **градиентного бустинга *LightGBM*** с количеством деревьев `n_estimators`=50 для признака `wnlpostag_text` (с *POS*-тегами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.730\n",
      "модель: LGBMClassifier 50\n",
      "данные: wnlpostag_text\n",
      "время работы модели: 49 s\n",
      "CPU times: total: 6min 3s\n",
      "Wall time: 50 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_lgbm50_pos = LGBMClassifier(n_estimators=50,\n",
    "                                  max_depth=10,\n",
    "                                  learning_rate=0.15,\n",
    "                                  class_weight='balanced', \n",
    "                                  boosting_type='gbdt', \n",
    "                                  objective='binary', \n",
    "                                  random_state=RANDOM_STATE,\n",
    "                                  # отключение прогресса обучения модели\n",
    "                                  verbose=-1)\n",
    "\n",
    "model_lgbm50_pos.mod = 'model_lgbm50_pos'\n",
    "model_lgbm50_pos.name = 'LGBMClassifier 50'\n",
    "model_lgbm50_pos.data = 'wnlpostag_text'\n",
    "model_lgbm50_pos.f1 = cross_val_score(model_lgbm50_pos, \n",
    "                                      tf_idf_train_pos, \n",
    "                                      target_train_pos, \n",
    "                                      cv=kfold, \n",
    "                                      scoring='f1')\n",
    "\n",
    "model_lgbm50_pos.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_lgbm50_pos.f1.mean()))\n",
    "print('модель:', model_lgbm50_pos.name)\n",
    "print('данные:', model_lgbm50_pos.data)\n",
    "print(f'время работы модели: {model_lgbm50_pos.time} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- метрика `f1`: 0.730\n",
    "- модель: `LGBMClassifier` \n",
    "- количество деревьев: `n_estimators` = 50\n",
    "- глубина дерева: `max_depth` = 10\n",
    "- коэффициент скорости обучения: `learning_rate` = 0.15\n",
    "- данные: `wnlpostag_text`  \n",
    "- время работы модели: 40 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"443\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "#### 4.4.3. `model_lgbm500`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **градиентного бустинга *LightGBM*** с количеством деревьев `n_estimators`=500 для признака `wnl_text` (без *POS*-тегов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.771\n",
      "модель: LGBMClassifier 500\n",
      "данные: wnl_text\n",
      "время работы модели: 236 s\n",
      "CPU times: total: 30min 44s\n",
      "Wall time: 3min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_lgbm500 = LGBMClassifier(n_estimators=500,\n",
    "                               max_depth=10,\n",
    "                               learning_rate=0.15,\n",
    "                               class_weight='balanced', \n",
    "                               boosting_type='gbdt', \n",
    "                               objective='binary', \n",
    "                               random_state=RANDOM_STATE,\n",
    "                               # отключение прогресса обучения модели\n",
    "                               verbose=-1)\n",
    "\n",
    "model_lgbm500.mod = 'model_lgbm500'\n",
    "model_lgbm500.name = 'LGBMClassifier 500'\n",
    "model_lgbm500.data = 'wnl_text'\n",
    "model_lgbm500.f1 = cross_val_score(model_lgbm500, \n",
    "                                   tf_idf_train, \n",
    "                                   target_train, \n",
    "                                   cv=kfold, \n",
    "                                   scoring='f1')\n",
    "\n",
    "model_lgbm500.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_lgbm500.f1.mean()))\n",
    "print('модель:', model_lgbm500.name)\n",
    "print('данные:', model_lgbm500.data)\n",
    "print(f'время работы модели: {model_lgbm500.time} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- метрика `f1`: 0.771\n",
    "- модель: `LGBMClassifier` \n",
    "- количество деревьев: `n_estimators` = 500\n",
    "- глубина дерева: `max_depth` = 10\n",
    "- коэффициент скорости обучения: `learning_rate` = 0.15\n",
    "- данные: `wnl_text`  \n",
    "- время работы модели: 179 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"444\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "#### 4.4.4. `model_lgbm500_pos`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **градиентного бустинга *LightGBM*** с количеством деревьев `n_estimators`=500 для признака `wnlpostag_text` (с *POS*-тегами)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.772\n",
      "модель: LGBMClassifier 500\n",
      "данные: wnlpostag_text\n",
      "время работы модели: 210 s\n",
      "CPU times: total: 27min 18s\n",
      "Wall time: 3min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "beg_time = datetime.datetime.now()\n",
    "\n",
    "model_lgbm500_pos = LGBMClassifier(n_estimators=500,\n",
    "                                   max_depth=10,\n",
    "                                   learning_rate=0.15,\n",
    "                                   class_weight='balanced', \n",
    "                                   boosting_type='gbdt', \n",
    "                                   objective='binary', \n",
    "                                   random_state=RANDOM_STATE,\n",
    "                                   # отключение прогресса обучения модели\n",
    "                                   verbose=-1)\n",
    "\n",
    "model_lgbm500_pos.mod = 'model_lgbm500_pos'\n",
    "model_lgbm500_pos.name = 'LGBMClassifier 500'\n",
    "model_lgbm500_pos.data = 'wnlpostag_text'\n",
    "model_lgbm500_pos.f1 = cross_val_score(model_lgbm500_pos, \n",
    "                                       tf_idf_train_pos, \n",
    "                                       target_train_pos, \n",
    "                                       cv=kfold, \n",
    "                                       scoring='f1')\n",
    "\n",
    "model_lgbm500_pos.time = (datetime.datetime.now()-beg_time).seconds\n",
    "\n",
    "print('f1: %.3f' %(model_lgbm500_pos.f1.mean()))\n",
    "print('модель:', model_lgbm500_pos.name)\n",
    "print('данные:', model_lgbm500_pos.data)\n",
    "print(f'время работы модели: {model_lgbm500_pos.time} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- метрика `f1`: 0.772\n",
    "- модель: `LGBMClassifier` \n",
    "- количество деревьев: `n_estimators` = 500\n",
    "- глубина дерева: `max_depth` = 10\n",
    "- коэффициент скорости обучения: `learning_rate` = 0.15\n",
    "- данные: `wnlpostag_text`  \n",
    "- время работы модели: 174 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"45\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 4.5. Сравнение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним модели и выберем лучшую, т.е. с наибольшим значением метрики *F1*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [model_lr, model_lr_pos, model_dt, model_dt_pos, \n",
    "              model_lgbm50, model_lgbm50_pos, model_lgbm500, model_lgbm500_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>data</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>cross_val_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_lr</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.752913</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lr_pos</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.752096</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_dt</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.61783</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_dt_pos</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.624639</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lgbm50</th>\n",
       "      <td>LGBMClassifier 50</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.724338</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lgbm50_pos</th>\n",
       "      <td>LGBMClassifier 50</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.730063</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lgbm500</th>\n",
       "      <td>LGBMClassifier 500</td>\n",
       "      <td>wnl_text</td>\n",
       "      <td>0.770725</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_lgbm500_pos</th>\n",
       "      <td>LGBMClassifier 500</td>\n",
       "      <td>wnlpostag_text</td>\n",
       "      <td>0.771799</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model            data  f1_score  \\\n",
       "model_lr               LogisticRegression        wnl_text  0.752913   \n",
       "model_lr_pos           LogisticRegression  wnlpostag_text  0.752096   \n",
       "model_dt           DecisionTreeClassifier        wnl_text   0.61783   \n",
       "model_dt_pos       DecisionTreeClassifier  wnlpostag_text  0.624639   \n",
       "model_lgbm50            LGBMClassifier 50        wnl_text  0.724338   \n",
       "model_lgbm50_pos        LGBMClassifier 50  wnlpostag_text  0.730063   \n",
       "model_lgbm500          LGBMClassifier 500        wnl_text  0.770725   \n",
       "model_lgbm500_pos      LGBMClassifier 500  wnlpostag_text  0.771799   \n",
       "\n",
       "                  cross_val_time  \n",
       "model_lr                       6  \n",
       "model_lr_pos                   7  \n",
       "model_dt                     175  \n",
       "model_dt_pos                 171  \n",
       "model_lgbm50                  56  \n",
       "model_lgbm50_pos              49  \n",
       "model_lgbm500                236  \n",
       "model_lgbm500_pos            210  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a={}\n",
    "for i in model_list:\n",
    "    b={}    \n",
    "    b['model']=i.name\n",
    "    b['data']=i.data\n",
    "    b['f1_score']=i.f1.mean()\n",
    "    b['cross_val_time']=i.time\n",
    "    a[i.mod] = b\n",
    "\n",
    "final_table = pd.DataFrame(a)\n",
    "\n",
    "display(final_table.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем в качестве лучшей модель **градиентного бустинга `LGBMClassifier`** `model_lgbm500_pos`, которая имеет следующее значение метрики оценки качества **на обучающей выборке**:\n",
    "\n",
    "- метрика `f1`: 0.772\n",
    "- модель: `LGBMClassifier` \n",
    "- количество деревьев: `n_estimators` = 500\n",
    "- глубина дерева: `max_depth` = 10\n",
    "- коэффициент скорости обучения: `learning_rate` = 0.15\n",
    "- данные: `wnlpostag_text`  \n",
    "- время работы модели: 174 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"46\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 4.6. Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В разделе [**Обучение моделей**](#4.-Обучение-моделей) были выполнены следующие задачи:\n",
    "1. Для обоих признаков `wnl_text` и `wnlpostag_text` данные разделены на обучающую и тестовую выборки.\n",
    "2. Для обоих признаков `wnl_text` и `wnlpostag_text` рассчитана величина *TF-IDF*.\n",
    "3. Для обоих признаков `wnl_text` и `wnlpostag_text`обучены восемь моделей (`LogisticRegression`, `DecisionTreeClassifier` и `LGBMClassifier` с количеством деревьев `n_estimators`=50 и `n_estimators`=500).\n",
    "4. Выведена таблица сравнения моделей.\n",
    "\n",
    "\n",
    "В результате выполнения задач этого раздела было выявлено следующее:\n",
    "- в качестве лучшей (с наибольшим значением метрики *F1*) выбрана модель **градиентного бустинга `LGBMClassifier`** `model_lgbm500_pos`, которая имеет следующее значение метрики оценки качества **на обучающей выборке**:\n",
    "\n",
    "    - метрика `f1`: 0.772\n",
    "    - модель: `LGBMClassifier` \n",
    "    - количество деревьев: `n_estimators` = 500\n",
    "    - глубина дерева: `max_depth` = 10\n",
    "    - коэффициент скорости обучения: `learning_rate` = 0.15\n",
    "    - данные: `wnlpostag_text`  \n",
    "    - время работы модели: 174 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"5\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "## 5. Тестирование лучшей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"51\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 5.1. Качество модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим лучшую модель **градиентного бустинга `LGBMClassifier`** `model_lgbm500_pos` **на тестовой выборке**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.775\n",
      "CPU times: total: 4min 48s\n",
      "Wall time: 37.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lgbm500_pos.fit(tf_idf_train_pos, target_train_pos)\n",
    "model_lgbm500_pos.predicted = model_lgbm500_pos.predict(tf_idf_test_pos)\n",
    "model_lgbm500_pos.test_f1 = f1_score(target_test_pos, model_lgbm500_pos.predicted)\n",
    "print('f1: %.3f' %(model_lgbm500_pos.test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- метрика `f1`: 0.775"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"52\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 5.2. Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В разделе [**Тестирование лучшей модели**](#5.-Тестирование-лучшей-модели) была протестирована лучшая модель градиентного бустинга `LGBMClassifier` `model_lgbm500_pos` с количеством деревьев `n_estimators`=500 для признака `wnlpostag_text` (с *POS*-тегами).\n",
    "   \n",
    "В результате выполнения задач этого раздела было выявлено следующее:\n",
    "- для выбранной лучшей модели значение метрики качества ***F1 = 0.775***, что превышает 0.75, как и изначально требовалось по условию задачи проекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"6\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "## 6. Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведено исследование с целью построения модели машинного обучения, которая поможет классифицировать комментарии на позитивные и негативные.\n",
    "\n",
    "Результаты исследования позволят магазину искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Входные данные: набор данных с разметкой о токсичности правок.\n",
    "\n",
    "В ходе исследования удалось получить следующие результаты **на обучающей выборке**:\n",
    "\n",
    "\n",
    "1. **Модель `LogisticRegression`**:\n",
    "\n",
    "   - данные, лемматизированые без учёта части речи - без *POS*-тегов (для признака `wnl_text`):\n",
    "      - *F1* = 0.753\n",
    "      - время работы модели: 5 s\n",
    "   - данные, лемматизированые с учётом части речи - с *POS*-тегами (для признака `wnlpostag_text`):\n",
    "      - *F1* = 0.752\n",
    "      - время работы модели: 5 s\n",
    "\n",
    "\n",
    "2. **Модель `DecisionTreeClassifier`** с глубиной дерева `max_depth` = 15:\n",
    "\n",
    "   - данные, лемматизированые без учёта части речи - без *POS*-тегов (для признака `wnl_text`):\n",
    "      - *F1* = 0.618\n",
    "      - время работы модели: 85 s\n",
    "   - данные, лемматизированые с учётом части речи - с *POS*-тегами (для признака `wnlpostag_text`):\n",
    "      - *F1* = 0.625\n",
    "      - время работы модели: 85 s\n",
    "\n",
    "\n",
    "3. **Модель `LGBMClassifier`** с глубиной дерева `max_depth` = 10 и коэффициентом скорости обучения `learning_rate` = 0.15:\n",
    "\n",
    "- количество деревьев **`n_estimators` = 50**:\n",
    "\n",
    "   - данные, лемматизированые без учёта части речи - без *POS*-тегов (для признака `wnl_text`):\n",
    "      - *F1* = 0.724\n",
    "      - время работы модели: 42 s\n",
    "   - данные, лемматизированые с учётом части речи - с *POS*-тегами (для признака `wnlpostag_text`):\n",
    "      - *F1* = 0.730\n",
    "      - время работы модели: 40 s\n",
    "\n",
    "\n",
    "- количество деревьев **`n_estimators` = 500**:\n",
    "\n",
    "   - данные, лемматизированые без учёта части речи - без *POS*-тегов (для признака `wnl_text`):\n",
    "      - *F1* = 0.771\n",
    "      - время работы модели: 179 s\n",
    "   - данные, лемматизированые с учётом части речи - с *POS*-тегами (для признака `wnlpostag_text`):\n",
    "      - *F1* = 0.772\n",
    "      - время работы модели: 174 s\n",
    "            \n",
    "      \n",
    "Исходя из полученных результатов, можно сделать следующие **выводы**:\n",
    "\n",
    "\n",
    "1. В качестве лучшей модели выбрана:\n",
    "   - модель **градиентного бустинга `LGBMClassifier`** `model_lgbm500_pos`, которая **на тестовой выборке** имеет следующее значение метрики оценки качества:\n",
    "    - ***F1 = 0.775*** \n",
    "   \n",
    "   \n",
    "2. Для выбранной лучшей модели значение метрики качества *F1* превышает 0.75, что соответсвует изначальному требованию в условии задачи проекта.\n",
    "   \n",
    "   \n",
    "**Общие рекомендации:**\n",
    "\n",
    "Магазину можно рекомендовать использовать полученную модель **`LGBMClassifier`** в качестве инструмента, который будет искать токсичные комментарии и отправлять их на модерацию."
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2196,
    "start_time": "2023-01-26T21:17:43.084Z"
   },
   {
    "duration": 4049,
    "start_time": "2023-01-26T21:17:45.283Z"
   },
   {
    "duration": 37,
    "start_time": "2023-01-26T21:17:49.334Z"
   },
   {
    "duration": 43,
    "start_time": "2023-01-26T21:17:49.373Z"
   },
   {
    "duration": 29,
    "start_time": "2023-01-26T21:17:49.419Z"
   },
   {
    "duration": 4,
    "start_time": "2023-01-26T21:17:49.450Z"
   },
   {
    "duration": 24853,
    "start_time": "2023-01-26T21:17:49.456Z"
   },
   {
    "duration": 102,
    "start_time": "2023-01-26T21:18:14.311Z"
   },
   {
    "duration": 3,
    "start_time": "2023-01-26T21:18:14.414Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "260px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.375px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
