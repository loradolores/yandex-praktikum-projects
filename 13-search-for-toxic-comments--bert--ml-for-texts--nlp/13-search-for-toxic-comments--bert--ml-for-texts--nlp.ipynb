{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Поиск токсичных комментариев (с BERT)\n",
    "\n",
    "<h2> (Тема №13: Машинное обучение для текстов) <a class=\"tocSkip\"> </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1. Содержание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1. Содержание](#1)\n",
    "\n",
    "[2. Описание проекта](#2)\n",
    "\n",
    "*    [2.1. Цель проекта](#21)\n",
    "*    [2.2. Задачи проекта](#22)\n",
    "*    [2.3. Описание данных](#23)\n",
    "*    [2.4. План работы](#24)\n",
    "\n",
    "[3. Подготовка данных](#3)\n",
    "\n",
    "*    [3.1. Изучение данных](#31)\n",
    "*    [3.2. Сэмплирование данных](#32)\n",
    "*    [3.3. Разделение сэмпла на выборки](#33)\n",
    "*    [3.4. Получение эмбеддингов (с *BERT*)](#34)\n",
    "*    [3.5. Вывод](#35)\n",
    "\n",
    "[4. Обучение и тестирование моделей](#4)\n",
    "\n",
    "*    [4.1. Функция для обучения моделей](#41)\n",
    "*    [4.2. `LogisticRegression`](#42)\n",
    "*    [4.3. `RandomForestClassifier`](#43)\n",
    "*    [4.4. `LGBMClassifier`](#44)\n",
    "*    [4.5. `CatBoostClassifier`](#45)\n",
    "*    [4.6. Сравнение моделей](#46)\n",
    "*    [4.7. Тестирование лучшей модели](#47)\n",
    "*    [4.8. Вывод](#48)\n",
    "\n",
    "[5. Общий вывод](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "## 2. Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Обучим модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Построим модель со значением метрики качества *F1* не меньше 0.75. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"21\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 2.1. Цель проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Провести исследование с целью построения модели машинного обучения, которая поможет классифицировать комментарии на позитивные и негативные.\n",
    "\n",
    "Результаты исследования позволят магазину искать токсичные комментарии и отправлять их на модерацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"22\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 2.2. Задачи проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Решим поставленную в проекте задачу **на базе нейронной сети *BERT***.\n",
    "\n",
    "1. Изучить данные.\n",
    "2. Сэмплировать данные.\n",
    "3. Разделить сэмплы на выборки.\n",
    "4. Получить эмбеддинги.\n",
    "5. Построить и обучить модели.\n",
    "6. Протестировать лучшую модель.\n",
    "7. Написать общий вывод.\n",
    "\n",
    "Построим модель со значением метрики качества *F1* не меньше 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"23\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 2.3. Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`.\n",
    "\n",
    "Столбец `text` в нём содержит текст комментария, а `toxic` — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"24\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 2.4. План работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Изучим данные.\n",
    "2. Сэмплируем данные: возьмём из датасета выборку из 1000 случайных элементов.\n",
    "3. Разделим сэмплированную выборку на обучающую и тестовую выборки в соотношении 4:1.\n",
    "4. Переведём текст комментариев в векторные представления (эмбеддинги) на базе нейронной сети *BERT*. Используем библиотеки  `torch` и `transformers`. Лемматизация для *BERT* не требуется.\n",
    "7. Обучим 4 модели: `LogisticRegression`, `RandomForestClassifier`, `LGBMClassifier` и `CatBoostClassifier` с различными гиперпараметрами.\n",
    "8. Сравненим модели.\n",
    "9. Протестируем лучшую модель и напишем вывод."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"3\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "## 3. Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score, \\\n",
    "GridSearchCV, KFold, train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tqdm import notebook\n",
    "\n",
    "RANDOM_STATE = 12345\n",
    "TEST_SIZE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"31\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 3.1. Изучение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv(r'C:/Users/lorad/OneDrive/Documents/Моя папка/Data Science/Курсы/'\n",
    "                        'Яндекс.Практикум. Специалист по Data Science/Проектная работа/'\n",
    "                        '13. Машинное обучение для текстов/toxic_comments.csv')\n",
    "except:\n",
    "    try:\n",
    "        data = pd.read_csv(r'D:/Юлия/Data Science/Курсы/'\n",
    "                            'Яндекс.Практикум. Специалист по Data Science/Проектная работа/'\n",
    "                            '13. Машинное обучение для текстов/toxic_comments.csv')\n",
    "    except:\n",
    "        data = pd.read_csv('https://docs.google.com/spreadsheets/d/e/'\n",
    "        '2PACX-1vQ59JmNL2DruMdFkZoOga-GFUBVFTSgDnVt4Pt7SErYdQQ7hHrTSzRaBHYMhpwa_K4xlnKs_8zrW6di/'\n",
    "                           'pub?gid=1802044232&single=true&output=csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140947</th>\n",
       "      <td>141099</td>\n",
       "      <td>Article proposal \\nTB, would you mind commenti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59738</th>\n",
       "      <td>59804</td>\n",
       "      <td>Please see the media as this is a blatantly ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147353</th>\n",
       "      <td>147509</td>\n",
       "      <td>AndyTheGrump either you are referring to the g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49616</th>\n",
       "      <td>49671</td>\n",
       "      <td>Woohoo! \\n\\nI'm a sysop! Thanks for letting me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141544</th>\n",
       "      <td>141697</td>\n",
       "      <td>Thanks for your reply:\\n \\n1- Who has raised t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               text  toxic\n",
       "140947      141099  Article proposal \\nTB, would you mind commenti...      0\n",
       "59738        59804  Please see the media as this is a blatantly ho...      0\n",
       "147353      147509  AndyTheGrump either you are referring to the g...      0\n",
       "49616        49671  Woohoo! \\n\\nI'm a sysop! Thanks for letting me...      0\n",
       "141544      141697  Thanks for your reply:\\n \\n1- Who has raised t...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет имеет большой размер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159292, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159292.000000</td>\n",
       "      <td>159292.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>79725.697242</td>\n",
       "      <td>0.101612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>46028.837471</td>\n",
       "      <td>0.302139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39872.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>79721.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>119573.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>159450.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0          toxic\n",
       "count  159292.000000  159292.000000\n",
       "mean    79725.697242       0.101612\n",
       "std     46028.837471       0.302139\n",
       "min         0.000000       0.000000\n",
       "25%     39872.750000       0.000000\n",
       "50%     79721.500000       0.000000\n",
       "75%    119573.250000       0.000000\n",
       "max    159450.000000       1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим наличие явных дубликатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитаем количество классов в таргете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдается сильный дисбаланс классов в таргете."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"32\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 3.2. Сэмплирование данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем решать поставленную в проекте задачу **на базе нейронной сети *BERT*** (от англ. *Bidirectional Encoder Representations from Transformers*, «двунаправленная нейронная сеть-кодировщик») — нейронная сеть для создания модели языка.\n",
    "\n",
    "Чтобы машины воспринимали слова, картинки или аудио, их преобразовывают в векторный вид. Когда работают с текстом, его тоже переводят в векторный формат, или векторные представления. Частный случай этих представлений — *word embeddings* (англ. «слова-вложения»; «эмбеддинги»). Работают они так: сложная структура (текст) вкладывается в более простую — вектор.\n",
    "Векторы-эмбеддинги содержат данные о соотношении разных слов и их свойствах. Привычное понимание свойства слова, его смысла и контекста справедливо и для машинного обучения. \n",
    "\n",
    "Чтобы не создавать эмбеддинги слишком долго, возьмём из датасета выборку из 1000 случайных элементов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = data.sample(\n",
    "    n=1000, random_state=RANDOM_STATE).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, сохранилось ли соотношение количества классов в таргете сэмплированной выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    890\n",
       "1    110\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"33\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 3.3. Разделение сэмпла на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим сэмплированную выборку `data_sample` на обучающую и тестовую выборки в соотношении 4:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры выборок:\n",
      "train - 800 - 80%\n",
      "test - 200 - 20%\n"
     ]
    }
   ],
   "source": [
    "data_sample_train, data_sample_test, y_train, y_test = train_test_split(\n",
    "    data_sample['text'], data_sample['toxic'], test_size=TEST_SIZE, \n",
    "    stratify=data_sample['toxic'], random_state=RANDOM_STATE)\n",
    "\n",
    "print('Размеры выборок:')\n",
    "print(f\"train - {len(data_sample_train)} \\\n",
    "- {len(data_sample_train)/len(data_sample['text']):.0%}\")\n",
    "\n",
    "print(f\"test - {len(data_sample_test)} \\\n",
    "- {len(data_sample_test)/len(data_sample['text']):.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"34\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 3.4. Получение эмбеддингов (с *BERT*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведём текст комментариев в векторные представления (эмбеддинги) **на базе нейронной сети *BERT***. Для этого используем модель [unitary/toxic-bert](https://huggingface.co/unitary/toxic-bert/tree/main), предобученную специально для идентификации токсичных комментариев. У *BERT* есть собственный токенизатор. Лемматизация для *BERT* не требуется.\n",
    "\n",
    "Решим задачу проекта на *PyTorch* (англ. «факел для Python»). Библиотека `torch` применяется в задачах обработки естественного текста и компьютерного зрения. А нам нужна для работы с моделью *BERT*, которая находится в библиотеке `transformers` (англ. «трансформеры»).\n",
    "\n",
    "Напишем функцию `get_embeddings()` для получения эмбеддингов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(data_sample): \n",
    "        \n",
    "    # Инициализируем токенизатор как объект класса BertTokenizer().\n",
    "    # Передадим ему аргумент vocab_file — это файл со словарём, \n",
    "    # на котором обучалась модель. Он может быть, например, \n",
    "    # в текстовом формате (txt). Зададим длину текстов max_length=512.\n",
    "    try:\n",
    "        tokenizer = transformers.BertTokenizer(vocab_file=r'C:/Users/lorad/OneDrive/'\n",
    "                                               'Documents/Моя папка/Data Science/Курсы/'\n",
    "                       'Яндекс.Практикум. Специалист по Data Science/Проектная работа/'\n",
    "                       '13. Машинное обучение для текстов/vocab.txt', max_length=512)\n",
    "    except:\n",
    "        tokenizer = transformers.BertTokenizer(vocab_file=r'D:/Юлия/Data Science/Курсы/'\n",
    "                       'Яндекс.Практикум. Специалист по Data Science/Проектная работа/'\n",
    "                       '13. Машинное обучение для текстов/vocab.txt', max_length=512)\n",
    "    \n",
    "    \n",
    "    # Токенизируем комментарии:    \n",
    "    \n",
    "    # Преобразуем текст в номера токенов из словаря методом encode() \n",
    "    # (англ. «закодировать»). Для корректной работы модели мы указали \n",
    "    # аргумент add_special_tokens=True (англ. «добавить специальные токены»).\n",
    "    # Это значит, что к любому преобразуемому тексту \n",
    "    # добавляется токен начала (101) и токен конца текста (102). \n",
    "    tokenized = data_sample.apply(\n",
    "        (lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "    \n",
    "    # Применим метод padding (англ. «отступ»), чтобы после токенизации \n",
    "    # длины исходных текстов в корпусе были равными. \n",
    "    # Только при таком условии будет работать модель BERT.\n",
    "    # Стандартная длина вектора будет max_len=512. \n",
    "    # Остальные векторы дополним нулями.\n",
    "    max_len = 512\n",
    "    padded = np.array([i + [0]*(max_len - len(i)) if len(i)<512 \\\n",
    "                       else i[:512] for i in tokenized.values])\n",
    "\n",
    "    \n",
    "    # Cоздадим маску для выделения важных токенов:\n",
    "    \n",
    "    # Поясним модели, что нули не несут значимой информации. Это нужно\n",
    "    # для компоненты модели, которая называется «внимание» (англ. attention).\n",
    "    # Отбросим эти токены и «создадим маску» для действительно важных \n",
    "    # токенов, то есть укажем нулевые и не нулевые значения.\n",
    "    attention_mask = np.where(padded != 0, 1, 0)\n",
    "\n",
    "    # отобразим размеры преобразованных данных\n",
    "    print(f\"tokenized shape: {tokenized.shape}\")\n",
    "    print(f\"padded shape: {padded.shape}\")\n",
    "    print(f\"attention_mask shape: {attention_mask.shape}\")\n",
    "    \n",
    "    \n",
    "    # Инициализируем конфигурацию BertConfig (англ. Bert Configuration). \n",
    "    # В качестве аргумента передадим ей JSON-файл с описанием настроек модели. \n",
    "    # JSON (англ. JavaScript Object Notation, «объектная запись JavaScript») — \n",
    "    # это организованный по ключам поток цифр, букв, двоеточий и фигурных \n",
    "    # скобок, который возвращает сервер при запросе. \n",
    "    try:\n",
    "        config = transformers.BertConfig.from_json_file(\n",
    "            r'C:/Users/lorad/OneDrive/Documents/Моя папка/Data Science/Курсы/'\n",
    "            'Яндекс.Практикум. Специалист по Data Science/Проектная работа/'\n",
    "            '13. Машинное обучение для текстов/config.json')\n",
    "    except:\n",
    "        config = transformers.BertConfig.from_json_file(\n",
    "            r'D:/Юлия/Data Science/Курсы/'\n",
    "            'Яндекс.Практикум. Специалист по Data Science/Проектная работа/'\n",
    "            '13. Машинное обучение для текстов/config.json')\n",
    "    \n",
    "    # Затем инициализируем саму модель класса BertModel. \n",
    "    # Передадим ей файл с предобученной моделью и конфигурацией.\n",
    "    try:\n",
    "        model = transformers.BertModel.from_pretrained(\n",
    "            r'C:/Users/lorad/OneDrive/Documents/Моя папка/Data Science/Курсы/'\n",
    "            'Яндекс.Практикум. Специалист по Data Science/Проектная работа/'\n",
    "            '13. Машинное обучение для текстов/pytorch_model.bin', config=config)\n",
    "    except:\n",
    "        model = transformers.BertModel.from_pretrained(\n",
    "            r'D:/Юлия/Data Science/Курсы/'\n",
    "            'Яндекс.Практикум. Специалист по Data Science/Проектная работа/'\n",
    "            '13. Машинное обучение для текстов/pytorch_model.bin', config=config)\n",
    "                \n",
    "    \n",
    "    # Модель BERT создаёт эмбеддинги батчами. Чтобы хватило оперативной памяти, \n",
    "    # сделаем размер батча небольшим: создадим эмбеддинги батчами по 20 текстов.\n",
    "    batch_size = 20\n",
    "    # Сделаем цикл по батчам. Отображать прогресс будет функция notebook().\n",
    "    # Cделаем пустой список для хранения эмбеддингов твитов.\n",
    "    embeddings = []\n",
    "    for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "            # Преобразуем данные в формат тензоров (англ. tensor) — многомерных  \n",
    "            # векторов в библиотеке torch. Тип данных LongTensor (англ. «длинный тензор») \n",
    "            # хранит числа в «длинном формате», то есть выделяет на каждое число 64 бита.\n",
    "            # Преобразуем данные.\n",
    "            batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "            # Преобразуем маску.\n",
    "            attention_mask_batch = torch.LongTensor(\n",
    "                attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "\n",
    "            \n",
    "            # Получим эмбеддинги для батча:\n",
    "            \n",
    "            # Для ускорения вычисления функцией no_grad() (англ. no gradient, \n",
    "            # «нет градиента») в библиотеке torch укажем, что градиенты не нужны -\n",
    "            # модель BERT обучать не будем.\n",
    "            with torch.no_grad():\n",
    "                # чтобы получить эмбеддинги для батча, передадим модели данные и маску\n",
    "                batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "            # Из полученного тензора извлечём нужные элементы и добавим в список \n",
    "            # всех эмбеддингов. Преобразуем элементы методом numpy() к типу numpy.array.\n",
    "            embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "    \n",
    "    # cоберём и выведем все эмбеддинги в матрицу признаков вызовом функции concatenate()\n",
    "    return np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим функцию `get_embeddings()` к обучающей выборке `data_sample_train`, получим эмбеддинги `X_train` - признаки для обучения моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized shape: (800,)\n",
      "padded shape: (800, 512)\n",
      "attention_mask shape: (800, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:/Users/lorad/OneDrive/Documents/Моя папка/Data Science/Курсы/Яндекс.Практикум. Специалист по Data Science/Проектная работа/13. Машинное обучение для текстов/pytorch_model.bin were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71dab1876b554bfeb7cb44ff6606384b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: (800, 768)\n",
      "CPU times: total: 2h 26min 13s\n",
      "Wall time: 18min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_train = get_embeddings(data_sample_train)\n",
    "print(f\"features shape: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим функцию `get_embeddings()` к тестовой выборке `data_sample_test`, получим эмбеддинги `X_test` - признаки для тестирования лучшей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized shape: (200,)\n",
      "padded shape: (200, 512)\n",
      "attention_mask shape: (200, 512)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:/Users/lorad/OneDrive/Documents/Моя папка/Data Science/Курсы/Яндекс.Практикум. Специалист по Data Science/Проектная работа/13. Машинное обучение для текстов/pytorch_model.bin were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9063aca593496a953f872f616ebe55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape: (200, 768)\n",
      "CPU times: total: 31min 57s\n",
      "Wall time: 6min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_test = get_embeddings(data_sample_test)\n",
    "print(f\"features shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"35\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 3.5. Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В разделе [**Подготовка данных**](#3.-Подготовка-данных) были выполнены следующие задачи:\n",
    "1. данные изучены;\n",
    "2. данные сэмплированы: из датасета взята выборка `data_sample` из 1000 случайных элементов;\n",
    "3. сэмплированная выборка разделена на обучающую и тестовую выборки в соотношении 4:1;\n",
    "4. получены эмбеддинги.\n",
    "\n",
    "\n",
    "В результате выполнения задач этого раздела было выявлено следующее:\n",
    "1. пропусков в данных нет;\n",
    "2. типы данных соответствуют их содержанию;\n",
    "3. датасет имеет большой размер: содержит 159 292 текстовых комментария;\n",
    "4. явных дубликатов нет;\n",
    "5. наблюдается сильный дисбаланс классов в таргете.\n",
    "\n",
    "**В проекте решается задача бинарной классификации.**\n",
    "\n",
    "Таким образом, данные подготовлены для обучения моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "## 4. Обучение и тестирование моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим четыре модели: логистическую регрессию (*Logistic Regression*), случайный лес (*Random Forest*), градиентные бустинги *LightGBM* и *CatBoost* для задачи классификации. Для обучения логистической регрессии используем функцию `cross_val_score()`, а для последних трёх моделей применим поиск гиперпараметров с помощью функции `GridSearchCV`.\n",
    "\n",
    "Учтём баланс классов в модели с помощью параметра `class_weight`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"41\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 4.1. Функция для обучения моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию `fit_model()` для обучения моделей `RandomForestClassifier`, `LGBMClassifier` и `CatBoostClassifier` и вычисления метрики качества *F1*. Метрика *F1* лучшей модели будет выводиться как `model.best_score_`. \n",
    "\n",
    "Используем разделение на фолды с помощью *KFold*. Зададим параметры для кроссвалидации: `n_splits` - количество фолдов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=3, random_state=RANDOM_STATE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(estimator, param_grid, X_train, y_train):\n",
    "    model = GridSearchCV(estimator=estimator,\n",
    "                         param_grid=param_grid,\n",
    "                         cv=kfold,\n",
    "                         scoring='f1')\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    best_f1 = round(model.best_score_, 2)\n",
    "\n",
    "    print(f\"Best F1: {best_f1}\")\n",
    "    print(f\"Best params: {model.best_params_}\")\n",
    "\n",
    "    return model.best_estimator_, best_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"42\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 4.2. `LogisticRegression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классифицируем обучающие данные с помощью модели **логистической регрессии *Logistic Regression*** - `LogisticRegression`. Используем функцию `cross_val_score()` для автоматизации предварительных преобразований данных перед обучением модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.93\n",
      "CPU times: total: 1.06 s\n",
      "Wall time: 434 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_lr = LogisticRegression(random_state=RANDOM_STATE, \n",
    "                              class_weight='balanced')\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "f1_lr = cross_val_score(model_lr, X_train, y_train,\n",
    "                        scoring='f1', cv=4).mean()\n",
    "\n",
    "print('F1:', f'{f1_lr:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель логистической регрессии **`LogisticRegression`** на обучающей выборке имеет следующее значение метрики оценки качества:\n",
    "- ***F1 = 0.93***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"43\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 4.3. `RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **случайного леса *Random Forest*** - `RandomForestClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.94\n",
      "Best params: {'max_depth': 7, 'n_estimators': 60}\n",
      "CPU times: total: 4.89 s\n",
      "Wall time: 4.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_estimator = RandomForestClassifier(random_state=RANDOM_STATE, \n",
    "                                      class_weight='balanced')\n",
    "\n",
    "rf_param_grid = {\n",
    "    # количество деревьев\n",
    "    'n_estimators': list(range(60, 121, 30)),\n",
    "    # максимальная глубина дерева\n",
    "    'max_depth': list(range(2, 13, 5)),\n",
    "}\n",
    "\n",
    "rf_best_model = fit_model(estimator=rf_estimator,\n",
    "                          param_grid=rf_param_grid,\n",
    "                          X_train=X_train,\n",
    "                          y_train=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая модель случайного леса **`RandomForestClassifier`** на обучающей выборке имеет следующее значение метрики оценки качества:\n",
    "- ***F1 = 0.94*** \n",
    "\n",
    "при следующих параметрах:\n",
    "- глубина дерева: `max_depth` = 7\n",
    "- количество деревьев: `n_estimators` = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"44\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 4.4. `LGBMClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **градиентного бустинга *LightGBM*** - `LGBMClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.94\n",
      "Best params: {'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100}\n",
      "CPU times: total: 6min 49s\n",
      "Wall time: 27.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lgbm_estimator = LGBMClassifier(random_state=RANDOM_STATE, \n",
    "                                class_weight='balanced')\n",
    "\n",
    "lgbm_param_grid = {\n",
    "    # количество деревьев (итераций)\n",
    "    \"n_estimators\": range(25, 101, 25), \n",
    "    # максимальная глубина дерева\n",
    "    \"max_depth\": range(5, 16, 5),\n",
    "    # коэффициент скорости обучения (размер шага градиентного спуска)\n",
    "    'learning_rate': [0.15, 0.2, 0.25]\n",
    "}\n",
    "\n",
    "lgbm_best_model = fit_model(estimator=lgbm_estimator,\n",
    "                            param_grid=lgbm_param_grid,\n",
    "                            X_train=X_train,\n",
    "                            y_train=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая модель градиентного бустинга **`LGBMClassifier`** на обучающей выборке имеет следующее значение метрики оценки качества:\n",
    "- ***F1 = 0.94***\n",
    "\n",
    "при следующих параметрах:\n",
    "- глубина дерева: `max_depth` = 5\n",
    "- количество деревьев: `n_estimators` = 100\n",
    "- коэффициент скорости обучения (размер шага градиентного спуска): `learning_rate` = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"45\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 4.5. `CatBoostClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим модель **градиентного бустинга *CatBoost*** - `CatBoostClassifier`.\n",
    "\n",
    "`CatBoostClassifier` создает временные файлы для обучения. Чтобы это предотвратить, и чтобы не появлялась ошибка о том, что по указанными путям у `CatBoostClassifier` нет доступа к созданию файлов, укажем в модели параметр `allow_writing_files=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1: 0.92\n",
      "Best params: {'depth': 4, 'iterations': 200, 'learning_rate': 0.15}\n",
      "CPU times: total: 34min 42s\n",
      "Wall time: 4min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight(class_weight='balanced', \n",
    "                               classes=classes, \n",
    "                               y=y_train)\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "catboost_estimator = CatBoostClassifier(random_state=RANDOM_STATE, \n",
    "                                        verbose=False, \n",
    "                                        class_weights=class_weights,\n",
    "                                        allow_writing_files=False)\n",
    "\n",
    "\n",
    "catboost_param_grid = {\n",
    "    # количество итераций\n",
    "    \"iterations\": range(100, 201, 50),\n",
    "    # глубина дерева\n",
    "    \"depth\": range(2, 7, 2),\n",
    "    # коэффициент скорости обучения (размер шага градиентного спуска)\n",
    "    \"learning_rate\": [0.1, 0.15, 0.2],\n",
    "}\n",
    "\n",
    "catboost_best_model = fit_model(estimator=catboost_estimator,\n",
    "                                param_grid=catboost_param_grid,\n",
    "                                X_train=X_train,\n",
    "                                y_train=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая модель градиентного бустинга **`CatBoostClassifier`** на обучающей выборке имеет следующее значение метрики оценки качества:\n",
    "- ***F1 = 0.92*** \n",
    "\n",
    "при следующих параметрах:\n",
    "- глубина дерева: `depth` = 4\n",
    "- количество итераций: `iterations` = 200\n",
    "- коэффициент скорости обучения (размер шага градиентного спуска): `learning_rate` = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"46\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 4.6. Сравнение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем значения метрики *F1* разных моделей на обучающей выборке в виде таблицы `table`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 для разных моделей\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model    F1\n",
       "0      LogisticRegression  0.93\n",
       "1  RandomForestClassifier  0.94\n",
       "2          LGBMClassifier  0.94\n",
       "3      CatBoostClassifier  0.92"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame([\n",
    "     ['LogisticRegression', f'{f1_lr:.2f}'],\n",
    "     ['RandomForestClassifier', f'{rf_best_model[1]:.2f}'],\n",
    "     ['LGBMClassifier', f'{lgbm_best_model[1]:.2f}' ],\n",
    "     ['CatBoostClassifier', f'{catboost_best_model[1]:.2f}']\n",
    "    ],\n",
    "columns=['model', 'F1'])\n",
    "\n",
    "print('F1 для разных моделей')\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве лучшей выберем модель **градиентного бустинга `LGBMClassifier`** со значением метрики ***F1 = 0.94***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"47\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 4.7. Тестирование лучшей модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим на тестовой выборке качество выбранной модели **градиентного бустинга `LGBMClassifier`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тестовой выборке: 0.95\n"
     ]
    }
   ],
   "source": [
    "f1_lgbm_test = f1_score(y_test, lgbm_best_model[0].predict(X_test))\n",
    "print('F1 на тестовой выборке:', f'{f1_lgbm_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая модель градиентного бустинга **`LGBMClassifier`** на тестовой выборке имеет следующее значение метрики оценки качества:\n",
    "- ***F1 = 0.95***\n",
    "\n",
    "Значение метрики *F1* на тестовой выборке превышает 0.75, что соответствует изначальному требованию в условии задачи проекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"48\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "### 4.8. Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В разделе [**Обучение и тестирование моделей**](#4.-Обучение-и-тестирование-моделей) были выполнены следующие задачи:\n",
    "1. написана функция `fit_model()` для обучения и вычисления метрики *F1* для моделей с использованием `GridSearchCV`;\n",
    "2. обучено четыре модели: `LogisticRegression`, `RandomForestClassifier`, `LGBMClassifier` и `CatBoostClassifier` с различными гиперпараметрами;\n",
    "3. качесто лучшей модели проверено на тестовой выборке.\n",
    "\n",
    "В результате выполнения задач этого раздела было выявлено следующее:\n",
    "1. В качестве лучшей выбрана модель **`LGBMClassifier`**, у которой на обучающей выборке значение метрики оценки качества ***F1 = 0,94***.\n",
    "2. Лучшая модель градиентного бустинга **`LGBMClassifier`** на тестовой выборке имеет следующее значение метрики оценки качества:\n",
    "- ***F1 = 0.95***\n",
    "\n",
    "Значение метрики *F1* на тестовой выборке превышает 0.75, что соответствует изначальному требованию в условии задачи проекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"5\"></a> <div style=\"text-align: right\">[Cодержание](#1.-Содержание)</div>\n",
    "## 5. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведено исследование с целью построения модели машинного обучения, которая поможет классифицировать комментарии на позитивные и негативные. Поставленная задача была решена **на базе нейронной сети *BERT***.\n",
    "\n",
    "Результаты исследования позволят магазину искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Входные данные: набор данных с разметкой о токсичности правок.\n",
    "\n",
    "В ходе исследования удалось получить следующие результаты **на обучающей выборке**:\n",
    "\n",
    "\n",
    "1. Модель логистической регрессии **`LogisticRegression`** имеет следующее значение метрики оценки качества:\n",
    "    - ***F1 = 0.93***\n",
    "\n",
    "\n",
    "2. Лучшая модель случайного леса **`RandomForestClassifier`** имеет следующее значение метрики оценки качества:\n",
    "    - ***F1 = 0.94*** \n",
    "\n",
    "   при следующих параметрах:\n",
    "    - глубина дерева: `max_depth` = 7\n",
    "    - количество деревьев: `n_estimators` = 60\n",
    "\n",
    "\n",
    "3. Лучшая модель градиентного бустинга **`LGBMClassifier`** имеет следующее значение метрики оценки качества:\n",
    "    - ***F1 = 0.94***\n",
    "\n",
    "   при следующих параметрах:\n",
    "    - глубина дерева: `max_depth` = 5\n",
    "    - количество деревьев: `n_estimators` = 100\n",
    "    - коэффициент скорости обучения (размер шага градиентного спуска): `learning_rate` = 0.15\n",
    "\n",
    "\n",
    "4. Лучшая модель градиентного бустинга **`CatBoostClassifier`** имеет следующее значение метрики оценки качества:\n",
    "    - ***F1 = 0.92*** \n",
    "\n",
    "   при следующих параметрах:\n",
    "    - глубина дерева: `depth` = 4\n",
    "    - количество итераций: `iterations` = 200\n",
    "    - коэффициент скорости обучения (размер шага градиентного спуска): `learning_rate` = 0.15\n",
    "      \n",
    "      \n",
    "Исходя из полученных результатов, можно сделать следующие **выводы**:\n",
    "\n",
    "\n",
    "1. В качестве лучшей модели выбрана:\n",
    "   - модель **градиентного бустинга `LGBMClassifier`**, которая **на тестовой выборке** имеет следующее значение метрики оценки качества:\n",
    "    - ***F1 = 0.95*** \n",
    "\n",
    "   \n",
    "2. Для выбранной лучшей модели значение метрики качества *F1* превышает 0.75, что соответсвует изначальному требованию в условии задачи проекта.\n",
    "   \n",
    "   \n",
    "**Общие рекомендации:**\n",
    "\n",
    "Магазину можно рекомендовать использовать полученную модель **`LGBMClassifier`** в качестве инструмента, который будет искать токсичные комментарии и отправлять их на модерацию."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.375px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
